{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "CAMeL_Tools_Guided_Tour.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "241d8892819246e383cd015108fd54e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92509a8e5f5749ca8d9e2a3d7e5d1177",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_237cfb02c0f1415480f5147ef1e65f84",
              "IPY_MODEL_ec535797d00e4917839abe4a21ffd244",
              "IPY_MODEL_6afff0832af24a26982b98753cc7581d"
            ]
          }
        },
        "92509a8e5f5749ca8d9e2a3d7e5d1177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "237cfb02c0f1415480f5147ef1e65f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55f226a89dc64f7c95af71d578736df6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c594b9d8ff6d45538159ea7f9717f071"
          }
        },
        "ec535797d00e4917839abe4a21ffd244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76a727b0bb824bf5a53bcba2cb931e89",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 23856,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 23856,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec54e6525bd543e8bd38fa855b4695ec"
          }
        },
        "6afff0832af24a26982b98753cc7581d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27cc94a5f99f4054810700011c94b2d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 139k/? [00:00&lt;00:00, 2.69MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_891590d54d5847d4a38f5d13c16f9304"
          }
        },
        "55f226a89dc64f7c95af71d578736df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c594b9d8ff6d45538159ea7f9717f071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76a727b0bb824bf5a53bcba2cb931e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec54e6525bd543e8bd38fa855b4695ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27cc94a5f99f4054810700011c94b2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "891590d54d5847d4a38f5d13c16f9304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acastellanos-ie/natural_language_processing/blob/master/tagging_parsing_practice/arabic_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCvwbQnTvBRh"
      },
      "source": [
        "# Google Colab Configuration\n",
        "\n",
        "**Execute this steps to configure the Google Colab environment in order to execute this notebook. It is not required if you are executing it locally and you have properly configured your local environment according to what explained in the Github Repository.**\n",
        "\n",
        "The first step is to clone the repository to have access to all the data and files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d7mC64KvlwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "298f3e85-a643-4e99-b095-53d60eb68525"
      },
      "source": [
        "! git clone https://github.com/acastellanos-ie/natural_language_processing.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'natural_language_processing'...\n",
            "remote: Enumerating objects: 4648, done.\u001b[K\n",
            "remote: Counting objects: 100% (4648/4648), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4455/4455), done.\u001b[K\n",
            "remote: Total 4648 (delta 271), reused 4476 (delta 161), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4648/4648), 12.98 MiB | 11.09 MiB/s, done.\n",
            "Resolving deltas: 100% (271/271), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ecfec2Y4v6e9"
      },
      "source": [
        "Install the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIep7l0jvtUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c777bd8-78c2-4f83-ed1f-650c7789a926"
      },
      "source": [
        "! pip install -Uqqr natural_language_processing/arabic_requirements.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.5MB 28.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.4MB 17.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 12.0MB 168kB/s \n",
            "\u001b[K     |████████████████████████████████| 10.8MB 27.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 34.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 41.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 727kB 32.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 454.3MB 24kB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3MB 153kB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.5MB 27.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8MB 33.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 36.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 25.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 983kB 32.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 266kB 49.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 471kB 43.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 19.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 33.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25h  Building wheel for camel-tools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for eli5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for stellargraph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for camel-kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 1.3.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: camel-tools 1.1.0 has requirement transformers==3.0.2, but you'll have transformers 4.8.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: ktrain 0.26.5 has requirement scikit-learn==0.23.2, but you'll have scikit-learn 0.22.2.post1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: ktrain 0.26.5 has requirement transformers<=4.3.3,>=4.0.0, but you'll have transformers 4.8.2 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHDzMQwpyODo"
      },
      "source": [
        "Now you have everything you need to execute the code in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c8-zs9m45B0"
      },
      "source": [
        "In order to use all the components provided in CAMeL Tools, we need to install all the datasets required by these components.\n",
        "To do this in Colab, we need to first mount a Google Drive and create a directory where the data will be installed.\n",
        "\n",
        "Run the code below and follow the instructions in the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLDEdYgz1OZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47601582-8174-483a-ff7a-8b0e1996afcf"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "%mkdir /gdrive/MyDrive/camel_tools"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fcc0ZaAK5f5F"
      },
      "source": [
        "Next, we need to tell CAMeL Tools to install the data in the newly created directory. This will take a couple of minutes to complete.\n",
        "\n",
        "**NOTE:** You will need at least 2.3GB of available space on your Google Drive to install all the CAMeL Tools data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYsFJl0A5mua"
      },
      "source": [
        "os.environ['CAMELTOOLS_DATA'] = '/gdrive/MyDrive/camel_tools'\n",
        "\n",
        "!export | camel_data full"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW2oOVmkJgg-"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook provides a quick overview of the different pre-processing steps needed to deal with textual contents in Arabic. It does not intend to be a full review but to provide you with illustrative examples and pointers to additional materials.\n",
        "\n",
        "To that end, I have used the guidelines and functionalities provided by [CAMeL Tools](https://github.com/CAMeL-Lab/camel_tools), one of the libraries that I recommended you to check.\n",
        "\n",
        "For more detailed information please refer to the [CAMeL Tools documentation](https://camel-tools.readthedocs.io/en/latest/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhD5hMgA088t"
      },
      "source": [
        "# Dediacritization\n",
        "\n",
        "Dediacritization is the process of removing Arabic diacritical marks. \n",
        "\n",
        "As discussed in class, Diacritics increase data sparsity and so most Arabic NLP techniques ignore them. The example below shows how diacritics can be removed from Arabic text using the [`dediac_ar`](https://camel-tools.readthedocs.io/en/latest/api/utils/dediac.html#camel_tools.utils.dediac.dediac_ar) function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np_JWmFq088u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0f8ad4b-3494-4af5-c8a4-fdb776e490b3"
      },
      "source": [
        "from camel_tools.utils.dediac import dediac_ar\n",
        "\n",
        "sentence = \"هَلْ ذَهَبْتَ إِلَى المَكْتَبَةِ؟\"\n",
        "print(sentence)\n",
        "\n",
        "sent_dediac = dediac_ar(sentence)\n",
        "print(sent_dediac)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "هَلْ ذَهَبْتَ إِلَى المَكْتَبَةِ؟\n",
            "هل ذهبت إلى المكتبة؟\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQw096Uw088u"
      },
      "source": [
        "# Tokenization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-Dr0J4W_-Bp"
      },
      "source": [
        "## Word Tokenization\n",
        "\n",
        "Tokenization is the step to split the entire sentence into the individual units of meaning (i.e., words). In class, we reviewed the standard process and the challenges it posed to Arabic.\n",
        "\n",
        "In this sense, there are different tokenization strategies that we can follow.\n",
        "\n",
        "Python does provide the `split()` method to tokenize words by whitespace, but it doesn't separate punctuation from words. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqLIIGGim5nm",
        "outputId": "9bf4bc2b-024a-4b28-9199-b6f5a105447e"
      },
      "source": [
        "sentence = \"هَلْ ذَهَبْتَ إِلَى المَكْتَبَةِ؟\"\n",
        "print(sentence)\n",
        "\n",
        "sent_split = sentence.split()\n",
        "print(sent_split)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "هَلْ ذَهَبْتَ إِلَى المَكْتَبَةِ؟\n",
            "['هَلْ', 'ذَهَبْتَ', 'إِلَى', 'المَكْتَبَةِ؟']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Sju7VQ6m3h5"
      },
      "source": [
        "A similar function to split by whitespace and separate punctuation is also provided by CAMeL Tools [`simple_word_tokenize`](https://camel-tools.readthedocs.io/en/latest/api/tokenizers/word.html#camel_tools.tokenizers.word.simple_word_tokenize).\n",
        "\n",
        "The example below is similar to the one above, but this time we use `simple_word_tokenize()` instead of `split()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxbPNRCU088v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ef28b9-95f7-4765-c55c-6a91e24c8279"
      },
      "source": [
        "from camel_tools.tokenizers.word import simple_word_tokenize\n",
        "\n",
        "sentence = \"هَلْ ذَهَبْتَ إِلَى المَكْتَبَةِ؟\"\n",
        "print(sentence)\n",
        "\n",
        "sent_split = simple_word_tokenize(sentence)\n",
        "print(sent_split)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "هَلْ ذَهَبْتَ إِلَى المَكْتَبَةِ؟\n",
            "['هَلْ', 'ذَهَبْتَ', 'إِلَى', 'المَكْتَبَةِ', '؟']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uuXeQjd0889"
      },
      "source": [
        "## Morphological Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmeKhpPVsI69"
      },
      "source": [
        "The tokenization strategies mentioned above are simply splitting sentences by whitespace and separating punctuation. However, this is not the best choice for Arabic. In contrast, morphological tokenization splits Arabic words into component prefixes, stems, and suffixes.\n",
        "\n",
        "CAMeL Tools provides the [`MorphologicalTokenizer`](https://camel-tools.readthedocs.io/en/latest/api/tokenizers/morphological.html#camel_tools.tokenizers.morphological.MorphologicalTokenizer) class to tokenize words in different schemes. It behaves very much like the `DefaultTagger` in that it uses a disambiguator first to disambiguate words and then extracts a particular tokenization feature, but it has the following differences:\n",
        "\n",
        "- While the `DefaultTagger` produces exactly one output for each input word, the `MorphologicalTokenizer` might produce multiple output tokens.\n",
        "-  The `MorphologicalTokenizer` can be configured to produce diacritized and undiacritized output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Upf_eeVE0889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035313c2-321a-443d-d61a-e1cc5e8ce1a0"
      },
      "source": [
        "from camel_tools.tokenizers.word import simple_word_tokenize\n",
        "from camel_tools.disambig.mle import MLEDisambiguator\n",
        "from camel_tools.tokenizers.morphological import MorphologicalTokenizer\n",
        "\n",
        "# The tokenizer expects pre-tokenized text\n",
        "sentence = simple_word_tokenize('فتنفست الصعداء')\n",
        "print(sentence)\n",
        "\n",
        "# Load a pretrained disambiguator to use with a tokenizer\n",
        "mle = MLEDisambiguator.pretrained('calima-msa-r13')\n",
        "\n",
        "# Without providing additional arguments, the tokenizer will output undiacritized\n",
        "# morphological tokens for each input word delimited by an underscore.\n",
        "tokenizer = MorphologicalTokenizer(mle, scheme='d3tok')\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)\n",
        "\n",
        "# By specifying `split=True`, the morphological tokens are output as seperate\n",
        "# strings.\n",
        "tokenizer = MorphologicalTokenizer(mle, scheme='d3tok', split=True)\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)\n",
        "\n",
        "# We can output diacritized tokens by setting `diac=True`\n",
        "tokenizer = MorphologicalTokenizer(mle, scheme='d3tok', split=True, diac=True)\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(tokens)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['فتنفست', 'الصعداء']\n",
            "['ف+_تنفست', 'ال+_صعداء']\n",
            "['ف+', 'تنفست', 'ال+', 'صعداء']\n",
            "['فَ+', 'تَنَفَّسْتُ', 'ال+', 'صُعَداءَ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMTRdw4g0888"
      },
      "source": [
        "# Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoYy16RApKQX"
      },
      "source": [
        "This step focuses on identifying the role of a given word in the context of a particular sentence. \n",
        "\n",
        "CAMeL Tools provides a [`DefaultTagger`](https://camel-tools.readthedocs.io/en/latest/api/tagger/default.html#camel_tools.tagger.default.DefaultTagger) for the POS Tagging of Arabic contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ToGeNYB0889",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9261e9d0-f545-4e81-ada8-9f023811327e"
      },
      "source": [
        "from camel_tools.tokenizers.word import simple_word_tokenize\n",
        "from camel_tools.disambig.mle import MLEDisambiguator\n",
        "from camel_tools.tagger.default import DefaultTagger\n",
        "\n",
        "mle = MLEDisambiguator.pretrained()\n",
        "tagger = DefaultTagger(mle, 'pos')\n",
        "\n",
        "# The tagger expects pre-tokenized text\n",
        "sentence = simple_word_tokenize('نجح بايدن في الانتخابات')\n",
        "\n",
        "pos_tags = tagger.tag(sentence)\n",
        "\n",
        "print(pos_tags)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['verb', 'noun_prop', 'prep', 'noun']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RweHalGCRRit"
      },
      "source": [
        "# Parsing\n",
        "\n",
        "If Tagging tries to discover the role of a word in a sentence, Parsing focuses on identifying the relationship between those different words.\n",
        "\n",
        "Several libraries are implementing this functionality. In the other notebook, we used spacy and NLTK for the Dependency Parsing of English text. However, not all these libraries offer this functionality for Arabic.\n",
        "\n",
        "In this sense, we will use [Stanza](https://stanfordnlp.github.io/stanza/), which includes a collection of NLP tools to a large variety of languages, Arabic among them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFkme3vTVd2A"
      },
      "source": [
        "The first thing to do is to import the Stanza library and to download the Arabic package. This package contains the different models and modules to perform the different NLP functionalities, including Dependency Parsing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "241d8892819246e383cd015108fd54e2",
            "92509a8e5f5749ca8d9e2a3d7e5d1177",
            "237cfb02c0f1415480f5147ef1e65f84",
            "ec535797d00e4917839abe4a21ffd244",
            "6afff0832af24a26982b98753cc7581d",
            "55f226a89dc64f7c95af71d578736df6",
            "c594b9d8ff6d45538159ea7f9717f071",
            "76a727b0bb824bf5a53bcba2cb931e89",
            "ec54e6525bd543e8bd38fa855b4695ec",
            "27cc94a5f99f4054810700011c94b2d7",
            "891590d54d5847d4a38f5d13c16f9304"
          ]
        },
        "id": "2KJ3fuppRXVe",
        "outputId": "12186a17-4226-4e83-ca28-b4ece690f00b"
      },
      "source": [
        "import stanza\n",
        "stanza.download('ar')   # This downloads the Arabic models for the neural pipeline"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "241d8892819246e383cd015108fd54e2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-19 15:16:46 INFO: Downloading default packages for language: ar (Arabic)...\n",
            "2021-07-19 15:16:48 INFO: File exists: /root/stanza_resources/ar/default.zip.\n",
            "2021-07-19 15:16:53 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ldJ27xLV2vr"
      },
      "source": [
        "Then, we can create a Pipeline (the basic Stanza object to execute all the NLP processes) using the arabic package that we have just downloaded\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSpRtxXoV1N8"
      },
      "source": [
        "nlp = stanza.Pipeline(\"ar\") # This sets up a default neural pipeline in Arabic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GefBntIaWO0W"
      },
      "source": [
        "Finally, we can analyze any sentence in arabic with the Pipeline object and pring the Dependency Parsing relationships."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwbHRYmXSFuq",
        "outputId": "801fd109-b37e-4b1d-c0a5-37a4a95ab023"
      },
      "source": [
        "doc = nlp(\"إمارة أبوظبي هي إحدى إمارات دولة الإمارات العربية المتحدة السبع.\")\n",
        "doc.sentences[0].print_dependencies()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('إمارة', 4, 'nsubj')\n",
            "('أبوظبي', 1, 'nmod')\n",
            "('هي', 4, 'nmod')\n",
            "('إحدى', 0, 'root')\n",
            "('إمارات', 4, 'nmod')\n",
            "('دولة', 5, 'nmod')\n",
            "('الإمارات', 6, 'nmod')\n",
            "('العربية', 7, 'amod')\n",
            "('المتحدة', 7, 'amod')\n",
            "('السبع', 7, 'nummod')\n",
            "('.', 4, 'punct')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jo6RMNz088_"
      },
      "source": [
        "# Named Entitiy Recognition\n",
        "\n",
        "Finally, CAMeL Tools comes with an easy-to-use, pretrained [named-entitity recognition](https://en.wikipedia.org/wiki/Named-entity_recognition)  (NER) system that can be accessed using the [`NERecognizer`](https://camel-tools.readthedocs.io/en/latest/api/ner.html#camel_tools.ner.NERecognizer) class. \n",
        "\n",
        "For each token in an input sentence, `NERecognizer` outputs a label that indicates the type of named-entity. The system outputs one of the following labels for each token: `'B-LOC'`, `'B-ORG'`, `'B-PERS'`, `'B-MISC'`, `'I-LOC'`, `'I-ORG'`, `'I-PERS'`, `'I-MISC'`, `'O'`.\n",
        "Named-entites can either be a `LOC` (location), `ORG` (organization), `PERS` (person), or `MISC` (miscallaneous).\n",
        "\n",
        "Labels beginning with `B` indicate that their corresponding tokens are the beginning of a multi-word named-entity or are a single-token named-entity'. Those begining with `I` indicate that their corresponding tokens are continuations of a multi-word named-entity. Words that aren't named-entities are given the `'O'` label.\n",
        "\n",
        "The example below illustrates how `NERecognizer` can be used to label named-entities in a given sentence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwBGDtiY088_",
        "outputId": "43b77f09-1e47-449e-bf9b-e383dc0e2754"
      },
      "source": [
        "from camel_tools.tokenizers.word import simple_word_tokenize\n",
        "from camel_tools.ner import NERecognizer\n",
        "\n",
        "ner = NERecognizer.pretrained()\n",
        "\n",
        "# NERecognizer expects pre-tokenized text\n",
        "sentence = simple_word_tokenize('إمارة أبوظبي هي إحدى إمارات دولة الإمارات العربية المتحدة السبع.')\n",
        "\n",
        "labels = ner.predict_sentence(sentence)\n",
        "\n",
        "# Print each token paired with it's NER label\n",
        "print(list(zip(sentence, labels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('إمارة', 'O'), ('أبوظبي', 'B-LOC'), ('هي', 'O'), ('إحدى', 'O'), ('إمارات', 'O'), ('دولة', 'O'), ('الإمارات', 'B-LOC'), ('العربية', 'I-LOC'), ('المتحدة', 'I-LOC'), ('السبع', 'O'), ('.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}