{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "day1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9potgKvrRNP"
      },
      "source": [
        "# Information Retrieval Practice\n",
        "\n",
        "Elasticsearch is an open-source distributed search server built on top of Apache Lucene. Itâ€™s a great tool that allows to quickly build applications with full-text search capabilities. The core implementation is in Java, but it provides a nice REST interface which allows to interact with Elasticsearch from any programming language.\n",
        "\n",
        "\n",
        "**Note: I do not recommend you to use Google Colab for this practice, but to execute everything locally in your computer. You will need to download, install and execute ElasticSearch, which is rather tricky to do in Colab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1lZGJa0rRNW"
      },
      "source": [
        "## Install Elastic Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmE0z13ArRNW"
      },
      "source": [
        "To install elastic search download your the package for your platform from Get Elasticsearch\n",
        " in https://www.elastic.co/es/start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2nYamg0rRNX"
      },
      "source": [
        "![](https://github.com/acastellanos-ie/MBD-EN-BL-ENE-2020-J-1/blob/master/ir_practice/download.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZQOFM9NrRNX"
      },
      "source": [
        "Once downloaded, unzip the tar.gz file and run `bin/elasticsearch` (or `bin\\elasticsearch.bat` on Windows). This will launch the ElasticSearch Server. Once the server is running, by default it's accessible at [localhost:9200](http://localhost:9200)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur_upbZ8rRNX"
      },
      "source": [
        "## Querying Elastic Search via Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdwWDzF3rRNY"
      },
      "source": [
        "To make queries to ElasticSearch you can directly query the server endpoint via REST. However, we can make it easier via the the `elasticsearch-py` Python library. This library provides a wrapper for the REST endpoint that will allow us to query the server form Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAJUZDWmrRNY"
      },
      "source": [
        "from elasticsearch import Elasticsearch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYUX9WoxrRNZ"
      },
      "source": [
        "# Exercise 0: Indexing and Searching Demo for ElasticSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l12YEcJGrRNZ"
      },
      "source": [
        "Now it's time to run some demo program. In this practice, we will create inverted index of sample documents (indexing) and then use Elasticsearch query grammar to search documents (searching)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lJysHnnrRNZ"
      },
      "source": [
        "### Useful functions\n",
        "\n",
        "Functions to facilitate the reading of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phTEJYoRrRNa"
      },
      "source": [
        "import os, io\n",
        "from collections import namedtuple\n",
        "\n",
        "# A document class with following attributes\n",
        "# filename: document filename\n",
        "# text: body of documment\n",
        "# path: path of document\n",
        "Doc = namedtuple('Doc', 'filename path text')\n",
        "\n",
        "def read_doc(doc_path, encoding):\n",
        "    '''\n",
        "        reads a document from path\n",
        "        input:\n",
        "            - doc_path : path of document\n",
        "            - encoding: encoding\n",
        "        output: =>\n",
        "            - doc: instance of Doc namedtuple\n",
        "    '''\n",
        "    filename = doc_path.split('/')[-1]\n",
        "    fp = io.open(doc_path, 'r', encoding = encoding)\n",
        "    text = fp.read().strip()\n",
        "    fp.close()\n",
        "    return Doc(filename = filename, text = text, path = doc_path)\n",
        "\n",
        "def read_dataset(path, encoding = \"ISO-8859-1\"):\n",
        "    '''\n",
        "        reads multiple documents from path\n",
        "        input:\n",
        "            - doc_path : path of document\n",
        "            - encoding: encoding\n",
        "        output: =>\n",
        "            - docs: instances of Doc namedtuple returned as generator\n",
        "    '''\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for doc_path in files:\n",
        "            yield read_doc(root + '/' + doc_path, encoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02lumg7hrRNa"
      },
      "source": [
        "##  Indexing\n",
        "\n",
        "We will try to index the sample documents in `./sample_documents`. To index the documents, we first need to make a connection to **Elasticsearch**. \n",
        "\n",
        "Before we index the documents, we first need to define the **configuration of elasticsearch**. During this process, you can define basic configuration of indexer such as tokenizer, stemmer, lemmatizer, and also define which search algorithm elasticsearch will use for search.\n",
        "\n",
        "Below code shows a simple configuration settings for this demo.\n",
        "The configuration tells elasticsearch that our document `doc` will have three fields `filename`, `path`, and `text`, and we will use `text` field for search. `my_analyzer` will be used to parse the `text` field, and `my_analyzer` will also be used as a search analyzer, which will parse search queries later on. `index:False` in `filename` and `path` fields tell elasticsearch that we will not index these two fields, therefore, we cannot search these two fields with queries. \n",
        "\n",
        "The detailed documentation of analyzer can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html).\n",
        "\n",
        "`\"similarity\": \"boolean\"` in `text` field will let elasticsearch know that we will use a boolean search algorithm to search `text` field. The detailed documentation of search algorithms can be found [here](https://www.elastic.co/guide/en/elasticsearch/reference/current/search.html)  and [here](https://www.elastic.co/guide/en/elasticsearch/guide/master/search-in-depth.html). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JCamONBrRNb"
      },
      "source": [
        "# configuration for indexing\n",
        "settings = {\n",
        "  \"mappings\": {\n",
        "      \"properties\": {\n",
        "        \"filename\": {\n",
        "          \"type\": \"keyword\",\n",
        "          \"index\": False,\n",
        "        },\n",
        "        \"path\": {\n",
        "          \"type\": \"keyword\",\n",
        "          \"index\": False,\n",
        "        },\n",
        "        \"text\": {\n",
        "          \"type\": \"text\",\n",
        "          \"similarity\": \"boolean\",\n",
        "          \"analyzer\": \"my_analyzer\",\n",
        "          \"search_analyzer\": \"my_analyzer\"\n",
        "        }\n",
        "      }\n",
        "  },    \n",
        "  \"settings\": {      \n",
        "    \"analysis\": {\n",
        "      \"analyzer\": {\n",
        "        \"my_analyzer\": {\n",
        "          \"filter\": [\n",
        "            \"lowercase\",\"stop\"\n",
        "          ],\n",
        "          \"type\": \"custom\",\n",
        "          \"tokenizer\": \"whitespace\",\n",
        "          \"char_filter\": [\"my_char_filter\"]\n",
        "        }\n",
        "      },\n",
        "      \"char_filter\": {\n",
        "        \"my_char_filter\": {\n",
        "          \"type\": \"html_strip\",\n",
        "          \"escaped_tags\": [\"b\"]\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woQfFuUDrRNc"
      },
      "source": [
        "Now we will retrieve `sample documents` and indexing them into `INDEX_NAME` index. To that end, the following 2 functions will help you in the creation of the index and the indexing of the documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "f2WTFAjDrRNd",
        "outputId": "cba78745-f619-4417-ac2a-4f35257ba3ae"
      },
      "source": [
        "ES_HOSTS = ['http://localhost:9200']\n",
        "INDEX_NAME = 'sample_index'\n",
        "DOCS_PATH = 'practice_data/sample_documents'\n",
        "\n",
        "def create_index(es_conn, index_name, settings):\n",
        "    '''\n",
        "        create index structure in elasticsearch server. \n",
        "        If index_name exists in the server, it will be removed, and new index will be created.\n",
        "        input:\n",
        "            - es_conn: elasticsearch connection object\n",
        "            - index_name: name of index to create\n",
        "            - settings: settings and mappings for index to create\n",
        "        output: =>\n",
        "            - None\n",
        "    '''\n",
        "    if es_conn.indices.exists(index_name):\n",
        "        es_conn.indices.delete(index = index_name)\n",
        "        print('index `{}` deleted'.format(index_name))\n",
        "    es_conn.indices.create(index = index_name, body = settings)\n",
        "    print('index `{}` created'.format(index_name))            \n",
        "            \n",
        "def build_index(es_conn, dataset, index_name, settings, DOC_TYPE='doc'):\n",
        "    '''\n",
        "        build index from a collection of documents\n",
        "        input:\n",
        "            - es_conn: elasticsearch connection object\n",
        "            - dataset: iterable, collection of namedtuple Doc objects\n",
        "            - index_name: name of the index where the documents will be stored\n",
        "            - DOC_TYPE: type signature of documents\n",
        "    '''\n",
        "    # create the index if it doesn't exist\n",
        "    create_index(es_conn = es_conn, index_name = index_name, settings=settings)\n",
        "    counter_read, counter_idx_failed = 0, 0 # counters\n",
        "\n",
        "    # retrive & index documents\n",
        "    for doc in dataset:\n",
        "        res = es_conn.index(\n",
        "            index = index_name,\n",
        "            id = doc.filename,\n",
        "            body = doc._asdict())\n",
        "        counter_read += 1\n",
        "\n",
        "        if res['result'] != 'created':\n",
        "            conter_idx_failed += 1\n",
        "        elif counter_read % 500 == 0:\n",
        "            print('indexed {} documents'.format(counter_read))\n",
        "\n",
        "    print('indexed {} docs to index `{}`, failed to index {} docs'.format(\n",
        "        counter_read,\n",
        "        index_name,\n",
        "        counter_idx_failed\n",
        "    ))\n",
        "    \n",
        "    # refresh after indexing\n",
        "    es_conn.indices.refresh(index=index_name)  \n",
        "\n",
        "es_conn = Elasticsearch(ES_HOSTS)\n",
        "dataset = read_dataset(DOCS_PATH)\n",
        "build_index(es_conn, dataset, INDEX_NAME, settings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index `sample_index` deleted\n",
            "index `sample_index` created\n",
            "indexed 1 documents\n",
            "indexed 2 documents\n",
            "indexed 3 documents\n",
            "indexed 4 documents\n",
            "indexed 5 documents\n",
            "indexed 5 docs to index `sample_index`, failed to index 0 docs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lad7DFftrRNg"
      },
      "source": [
        "We successfully created an inverted index for the sample documents in `./sample/documents`. It's time to search the documents with some queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBmosIGcrRNh"
      },
      "source": [
        "## Searching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVp45dV5rRNh"
      },
      "source": [
        "**Elasticsearch** supports a specific query grammar which intends to replicate the grammar of traditional search engines (Google Search supports a similar grammar).\n",
        "https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html\n",
        "\n",
        "To understand score of the result, check: https://www.elastic.co/guide/en/elasticsearch/guide/current/relevance-intro.html#explain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrBIwOsyrRNh"
      },
      "source": [
        "### Useful Functions\n",
        "\n",
        "These functions will help you with the ElasticSearch output format in order to visualize the search results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkUtCZS7rRNh"
      },
      "source": [
        "def extract_response(res):\n",
        "    if res is not None:\n",
        "        for hit in res['hits']['hits']:\n",
        "            filename = hit[\"_source\"][\"filename\"]\n",
        "            score = hit[\"_score\"]\n",
        "            \n",
        "            yield (filename, score)\n",
        "\n",
        "def print_result(query, res):\n",
        "    # formatter of searched result\n",
        "    matches = extract_response(res)\n",
        "    if matches is not None:\n",
        "        for match in sorted(matches, key = lambda x: -x[1]):\n",
        "            print('{}, {}, {},\\n'.format(\n",
        "                query,\n",
        "                match[0], # filename\n",
        "                match[1], # score\n",
        "            ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_t9qyRArRNi"
      },
      "source": [
        "We will perform now different types of queries.\n",
        "\n",
        "First, a query with a single term"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toIMY3RPrRNi",
        "outputId": "9ad668ab-ec99-46a6-b2f2-26ca64e95f7c"
      },
      "source": [
        "res = es_conn.search(index = INDEX_NAME,\n",
        "    body={\n",
        "          \"query\": {\n",
        "            \"bool\": {\n",
        "              \"must\": [\n",
        "                {\n",
        "                  \"match\": {\"text\": \"Obama\"}\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "    )\n",
        "print_result(\"Obama\", res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obama, doc1.txt, 1.0,\n",
            "\n",
            "Obama, doc3.txt, 1.0,\n",
            "\n",
            "Obama, doc5.txt, 1.0,\n",
            "\n",
            "Obama, doc2.txt, 1.0,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXGq65SdrRNj"
      },
      "source": [
        "Now a query for the documents containing both terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoXC7BAhrRNj",
        "outputId": "9edd5d63-6a88-4dd9-93e8-465557b23c34"
      },
      "source": [
        "# Boolean Query \"Obama AND Hillary\"\n",
        "res = es_conn.search(index = INDEX_NAME,\n",
        "    body={\n",
        "          \"query\": {\n",
        "            \"match\" : {\n",
        "              \"text\" : {\n",
        "                \"query\" : \"Obama Hillary\",\n",
        "                \"operator\" : \"and\"\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "    )\n",
        "print_result(\"Obama AND Hillary\", res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obama AND Hillary, doc1.txt, 2.0,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t6Dw1ssrRNk"
      },
      "source": [
        "And now containing a term but NOT the other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euFJtG9OrRNk",
        "outputId": "5b2d22eb-821e-4241-f349-bdc704b14275"
      },
      "source": [
        "# Boolean Query \"Obama BUT Hillary\"\n",
        "res = es_conn.search(index = INDEX_NAME,\n",
        "    body={\n",
        "          \"query\": {\n",
        "            \"bool\": {\n",
        "              \"must\": [\n",
        "                {\n",
        "                    \"match\": {\"text\": \"Obama\"}\n",
        "                }\n",
        "              ],\n",
        "              \"must_not\":[\n",
        "                {\n",
        "                    \"match\": {\"text\": \"Hillary\"}\n",
        "                }\n",
        "              ]\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "    )\n",
        "print_result(\"Obama BUT Hillary\", res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obama BUT Hillary, doc3.txt, 1.0,\n",
            "\n",
            "Obama BUT Hillary, doc5.txt, 1.0,\n",
            "\n",
            "Obama BUT Hillary, doc2.txt, 1.0,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM_KgFKprRNl"
      },
      "source": [
        "Finally, the default behaviour for queries with more than one term: OR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrtfnSDmrRNl",
        "outputId": "741a7c6b-e913-427f-b8b7-b4b00e4a3137"
      },
      "source": [
        "# Boolean Query \"Obama OR Hillary\"\n",
        "# default is OR\n",
        "res = es_conn.search(index = INDEX_NAME,\n",
        "    body={\n",
        "          \"query\": {\n",
        "            \"match\" : {\n",
        "              \"text\" : {\n",
        "                \"query\" : \"Obama Hillary\",\n",
        "              }\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "    )\n",
        "print_result(\"Obama OR Hillary\", res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obama OR Hillary, doc1.txt, 2.0,\n",
            "\n",
            "Obama OR Hillary, doc3.txt, 1.0,\n",
            "\n",
            "Obama OR Hillary, doc5.txt, 1.0,\n",
            "\n",
            "Obama OR Hillary, doc4.txt, 1.0,\n",
            "\n",
            "Obama OR Hillary, doc2.txt, 1.0,\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}